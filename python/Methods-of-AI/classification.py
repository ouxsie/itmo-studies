# -*- coding: utf-8 -*-
"""ЛР 2 методы ии.ipyb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16vtPmBb6BKnPbDWDsPu4Wo2-kTfgY5Gm

# **Лабораторная работа 2. Классификация в машинном обучении.**

Выбранный датасет: 1.2 Набор данных B: Текстовые данные (Средний уровень) AG News Classification - datasets.load_dataset("ag_news")

Импорт библиотек
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datasets import load_dataset
from collections import Counter
import re

"""Подготовка датасета"""

dataset = load_dataset("ag_news")

print("Доступные сплиты:", list(dataset.keys()))
print("\nТип объекта:", type(dataset))

train_dataset = dataset['train']
test_dataset = dataset['test']

print(f"\nРазмер тренировочного набора: {len(train_dataset)}")
print(f"Размер тестового набора: {len(test_dataset)}")
print(f"Общий размер датасета: {len(train_dataset) + len(test_dataset)}")

# Просмотр структуры
print("\nСтруктура:")
print(train_dataset.features)

"""**Задача 1: EDA и предобработка данных**"""

from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer

train_df = pd.DataFrame(train_dataset)
test_df = pd.DataFrame(test_dataset)

label_names = {
    0: "World",
    1: "Sports",
    2: "Business",
    3: "Sci/Tech"
}

print(f"Размеры: train {train_df.shape}, test {test_df.shape}")
print("Распределение классов:", train_df['label'].value_counts().sort_index())

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
train_df['label'].value_counts().plot(kind='bar')
plt.title('Распределение классов')

plt.subplot(1, 2, 2)
train_df['text'].str.len().hist(bins=50)
plt.title('Длина текстов')
plt.tight_layout()
plt.show()

def get_top_words(texts, n=20):
    all_words = ' '.join(texts).lower().split()
    word_freq = Counter(all_words)
    return word_freq.most_common(n)

top_words = get_top_words(train_df['text'])
words, counts = zip(*top_words)

plt.figure(figsize=(10, 8))
plt.barh(words[:15], counts[:15], color='purple', alpha=0.7)
plt.title('15 самых частых слов в датасете')
plt.xlabel('Частота')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()


# Облако слов для каждого класса
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
for i, (label, name) in enumerate(label_names.items()):
    row, col = i // 2, i % 2
    class_texts = ' '.join(train_df[train_df['label'] == label]['text'])
    wordcloud = WordCloud(width=400, height=300, background_color='white',
                         max_words=100).generate(class_texts)
    axes[row, col].imshow(wordcloud, interpolation='bilinear')
    axes[row, col].set_title(f'Облако слов: {name}')
    axes[row, col].axis('off')

plt.tight_layout()
plt.show()

# Предобработка и векторизация (TfidVectorizer по умолчанию включает токенизацию, стоп-слова уточнены параметром)
vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
X_train = vectorizer.fit_transform(train_df['text'])
X_test = vectorizer.transform(test_df['text'])
y_train, y_test = train_df['label'], test_df['label']

print(f"Векторизованные данные: {X_train.shape}")

"""**Задача 2: разработка базовых моделей**"""

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

models = {
    'Logistic Regression': LogisticRegression(max_iter=500, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=50, random_state=42),
    'Naive Bayes': MultinomialNB()
}

# Обучение и оценка
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"{name}: {accuracy:.4f}")

"""**Задача 3: оценка модели**"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# Разделение на train/val
X_temp, X_val, y_temp, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Оценка лучшей модели
best_model = LogisticRegression(max_iter=500, random_state=42)
best_model.fit(X_temp, y_temp)
y_pred = best_model.predict(X_val)

print("Accuracy:", accuracy_score(y_val, y_pred))
print("\nClassification Report:")
print(classification_report(y_val, y_pred))

# Матрица ошибок
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_val, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.show()

"""**Задача 4: Настройка гиперпараметров**"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'C': [0.1, 1, 10],
    'solver': ['liblinear', 'lbfgs']
}

grid_search = GridSearchCV(LogisticRegression(max_iter=500, random_state=42),
                          param_grid, cv=3, scoring='accuracy')
grid_search.fit(X_temp, y_temp)

print("Лучшие параметры:", grid_search.best_params_)
print("Лучшая точность:", grid_search.best_score_)

# Финальная оценка на тесте
final_model = grid_search.best_estimator_
final_model.fit(X_train, y_train)
y_test_pred = final_model.predict(X_test)
print(f"Финальная точность на тесте: {accuracy_score(y_test, y_test_pred):.4f}")

"""**Ансамбли***"""

from sklearn.ensemble import VotingClassifier

voting_clf = VotingClassifier(
    estimators=[
        ('lr', LogisticRegression(C=1, solver='liblinear', random_state=42)),
        ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),
        ('nb', MultinomialNB())
    ],
    voting='soft'
)

voting_clf.fit(X_temp, y_temp)
y_vote_pred = voting_clf.predict(X_val)
print(f"Voting Classifier Accuracy: {accuracy_score(y_val, y_vote_pred):.4f}")

models['Voting'] = voting_clf

for name, model in models.items():
    if name != 'Voting':
        model.fit(X_temp, y_temp)
    y_pred = model.predict(X_val)
    print(f"{name:20}: {accuracy_score(y_val, y_pred):.4f}")
